################################################
#          UChicago DSaPP Police EIS           #
#              Model experiments               #
################################################

make_feat_dists: False  # Whether you would like distributions of 1 / 0 classes made of training set features
distdir: dists  # Where to put them

########################
# Type of Experiment   #
########################

unit: 'officer'  # other options: 'dispatch'
aggregation: False  # Also produce unit and division level risk scores
pilot: False  # Turn on pilot experiment
pilot_today: '01May2016'  # Do pilot beginning date
pilot_dir: 'pilot/'

########################
# Temporal parameters  #
########################

fake_today: ['01May2014', '01May2013']  # if you want a specific_today then pass this
autogen_fake_todays: False  # set to off if you want a specific fake_today
training_window: [365, 730, 10000]  # training, days, used for officer-level prediction
prediction_window: [365, 180]  # prediction, days, used for officer-level prediction
testing_interval_days: 365  # days, used for dispatch-level prediction
training_interval_days: 1460  # days, used for dispatch-level prediction
# 1 year = 365, 2 year = 730, 3 year = 1095, 4 year = 1460

########################
# Labelling Details    #
########################

# Select which events you want the model to use as adverse incidents (class 1)

def_adverse:
    accidents: False  # preventable accidents
    useofforce: False  # unjustified use of force
    injury: False  # preventable officer injuries
    icd: False  # preventable in custody deaths
    tdd: False  # unjustified use of tire deflation device
    nfsi: False  # unjustified no force subject injury
    dof: False  # unjustified discharge of firearm
    raid: False  # unjustified raid and search
    pursuit: False  # unjustified pursuit
    complaint: True  # sustained complaints

labelling:
    include_all_employed: True # include all officers who were employed during the specified period
    include_all_active: True # include all oficcers who made an arrest or stop during the specified period.

########################
# Feature selection    #
########################
try_feature_sets_by_group: False  # Turn on if you want the code to try removing each feature set in turn

officer_features:
    AcademyScore: True # Performance score at the police academy.
    DivorceCount: True # Number of total divorces in this officer's past.
    MilesFromPost: True # Number of miles to post.
    OfficerRace: True # Officer race code
    OfficerGender: True # Officer gender code

    ArrestCountCareer: True # Career arrests of officer
    ArrestCount1Yr: True # Number of arrests in last year.
    IncidentCount: True # Officer investigatable incident count to fake_today
    SustainedRuleViolations: True # Officer investigatable incident count to fake_today

    MeanHoursPerShift: True # Average number of hours per shift
    AllAllegations: True # Number of allegations made against an officer
# empty feature groups break the code, so for now, we're
# commenting out all feature groups that have no
# features defined.
#
#    ia:
#
#    unit_div:
#
#    citations:
#
#    incidents:
#
#    field_interviews:
#
#    cad:
#
#    training:
#
#    traffic_stops:
#
#    eis:
#
#    neighborhood:

########################
# Model selection      #
########################
#model: ['RandomForest']
# parameters:
#   RandomForest:
#    n_estimators: [10]
#    depth: [10]

# model: ['SVM']
# parameters:
#   SVM:
#     C_reg: [100.0]
#     kernel: ['linear']

#model: ['ExtraTrees', 'AdaBoost',
#        'LogisticRegression', 'SVM', 'GradientBoostingClassifier',
#        'DecisionTreeClassifier',
#        'SGDClassifier', 'KNeighborsClassifier']
model: ['RandomForest']
parameters:
  RandomForest:
    n_estimators: [10 ] # , 25, 50, 100]  # [1000, 10000]
    max_depth: [5] # , 10, 20]  # 50, 100
    max_features: ['sqrt'] # 'log2']  # [2, 4, 8, 16, "auto"]
    criterion: ['gini' ] #'entropy']
    min_samples_split: [2] # 5, 10]
  ExtraTrees:
    n_estimators: [1, 10, 25, 50, 100]  # [1000, 10000]
    max_depth: [1, 3, 5, 10, 20]  # 50, 100
    max_features: ['sqrt', 'log2']  # [2, 4, 8, 16, "auto"]
    criterion: ['gini', 'entropy']
    min_samples_split: [2, 5, 10]
  AdaBoost:
    algorithm: ['SAMME', 'SAMME.R']
    n_estimators: [1, 10, 100]  # [1000, 10000]
    learning_rate: [0.01, 0.1, 1, 10, 100]
  LogisticRegression:
    C_reg: [0.00001, 0.0001, 0.001, 0.01, 0.1]  # [1, 10]
    penalty: ['l1', 'l2']
  SVM:
    C_reg: [0.00001, 0.0001, 0.001, 0.01, 0.1]  # [1, 10]
    kernel: ['linear']
  GradientBoostingClassifier:
    n_estimators: [1, 10, 100]  # [1000, 10000]
    learning_rate: [0.001, 0.01, 0.05, 0.1, 0.5]
    subsample: [0.1, 0.5, 1.0]
    max_depth: [1, 3, 5, 10, 20]  # [50, 100]
  DecisionTreeClassifier:
    criterion: ['gini', 'entropy']
    max_depth: [1, 5, 10, 20]  # [50, 100]
    max_features: ['sqrt', 'log2']
    min_samples_split: [2, 5, 10]
  SGDClassifier:
    loss: ['log', 'modified_huber']
    penalty: ['l1', 'l2', 'elasticnet']
  KNeighborsClassifier:
    n_neighbors: [1, 3, 5, 10, 25, 50, 100]
    weights: ['uniform', 'distance']
    algorithm: ['auto', 'kd_tree']


########################
# Parallelization      #
########################
n_cpus: 4

########################
# Output file details  #
########################
directory: 'results/'
pkl_prefix: 'police_eis_results'

########################
# Auditing hooks       #
########################
auditing: False  # Turn on if you want auditing performed
audits: 'audits/'
